<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DeepSieve: LLM-as-Router for Modular RAG</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Google+Sans&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Google Sans', sans-serif;
      padding-bottom: 100px;
    }
    .hero-body {
      padding: 3rem 1.5rem;
    }
    .subtitle {
      color: #555;
    }
    .section {
      padding-top: 3rem;
      padding-bottom: 3rem;
    }
    .image-container {
      width: 100%;
      max-width: 1000px;
      margin: 0 auto;
    }
    .image-container img {
      width: 100%;
      height: auto;
      object-fit: contain;
      max-height: 600px;
    }
  </style>
</head>

<body>
 <section class="hero is-light">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">DeepSieve <span class="has-text-grey is-size-4">Ê∑±Â∫¶Ê∑òÊºâ</span></h1>
      <h2 class="subtitle is-4">Information Sieving via LLM-as-a-Knowledge-Router</h2>

      <p class="is-italic mt-3">
        ‚ÄúThrough countless siftings, though laborious, only when the wild sands are blown away, does gold appear.‚Äù<br>
        <span class="has-text-grey">ÂçÉÊ∑ò‰∏áÊºâËôΩËæõËã¶ÔºåÂêπÂ∞ΩÁãÇÊ≤ôÂßãÂà∞Èáë</span>
      </p>

      <div class="buttons is-centered mt-4">
        <a href="https://arxiv.org/abs/2507.22050" class="button is-link is-light">Paper</a>
        <a href="https://github.com/MinghoKwok/DeepSieve" class="button is-dark is-light">Code</a>
      </div>
    </div>
  </div>
</section>



  <section class="section">
    <div class="container">
      <h2 class="title is-3">Authors</h2>
      <div class="content">
        <div class="columns is-multiline">
          <div class="column is-full">
            <p class="is-size-5">
              Minghao Guo<sup>1</sup>,
              Qingcheng Zeng<sup>2</sup>,
              Xujiang Zhao<sup>3</sup>,
              Yanchi Liu<sup>3</sup>,
              Wenchao Yu<sup>3</sup>,
              Mengnan Du<sup>4</sup>,
              Haifeng Chen<sup>3</sup>,
              Wei Cheng<sup>3</sup>*
            </p>
          </div>
          <div class="column is-full mt-2">
            <p class="is-size-6">
              <sup>1</sup>Rutgers University &nbsp;&nbsp;
              <sup>2</sup>Northwestern University &nbsp;&nbsp;
              <sup>3</sup>NEC Laboratories America &nbsp;&nbsp;
              <sup>4</sup>NJIT
            </p>
            <p class="is-size-6 mt-2">
              *Corresponding Author: <a href="mailto:weicheng@nec-labs.com">weicheng@nec-labs.com</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  
  <section class="section">
    <div class="container">
      <h2 class="title is-3">Overview</h2>
      <p class="content">
        DeepSieve is a modular Retrieval-Augmented Generation (RAG) framework that enhances LLM-based reasoning across heterogeneous knowledge sources. It introduces a multi-stage <strong>information sieving pipeline</strong>:
        <strong>Decompose ‚Üí Route ‚Üí Reflexion ‚Üí Fusion</strong>. Each subquery is dynamically routed to the most suitable (Tool, Corpus) pair. If retrieval fails, DeepSieve reroutes or replans to ensure robust answers.
      </p>
    </div>
  </section>

  <section class="section" id="workflow">
    <div class="container">
      <h2 class="title is-3">System Architecture</h2>
      <div class="image-container">
        <img src="./static/images/Workflow.png" alt="DeepSieve architecture diagram">
      </div>
      <p class="content mt-4">
        DeepSieve executes a multi-hop reasoning DAG where each subquery selects its optimal knowledge route. Reflexion enables recovery from retrieval failure. Fusion aggregates validated answers into a final response.
      </p>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3">Core Modules</h2>
      <div class="content">
        <ul>
          <li><strong>Decomposition:</strong> Breaks the query into a DAG of sub-questions using an LLM planner.</li>
          <li><strong>Routing:</strong> Selects (Tool, Corpus) pairs for each subquestion based on profiles and history.</li>
          <li><strong>Reflexion:</strong> Re-evaluates failed queries by retrying alternate sources.</li>
          <li><strong>Fusion:</strong> Merges validated subanswers into a coherent final output.</li>
        </ul>
      </div>
    </div>
  </section>

  <section class="section" id="results">
    <div class="container">
      <h2 class="title is-3">Results</h2>
      <p class="content">
        DeepSieve achieves state-of-the-art performance on MuSiQue, 2Wiki, and HotpotQA under both DeepSeek-V3 and GPT-4o backbones.
      </p>
      <div class="image-container">
        <img src="./static/images/Exp_Agentic_Radar.png" alt="Performance radar chart">
      </div>
      <ul class="mt-4">
        <li><strong>MuSiQue F1:</strong> 46.8 (+13.4 over best baseline)</li>
        <li><strong>2Wiki F1:</strong> 68.4 (+5.3)</li>
        <li><strong>HotpotQA F1:</strong> 61.6</li>
      </ul>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2 class="title is-3">Example</h2>
      <p class="content">
        <strong>Query:</strong> What country is the birthplace of Erik Hort a part of?<br>
        <strong>Pure RAG:</strong> Incorrect or hallucinated answer.<br>
        <strong>DeepSieve Reasoning Chain:</strong>
        <ol>
          <li>Q1: Who was born in Montebello? ‚Üí Erik Hort</li>
          <li>Q2: What state is Montebello in? ‚Üí New York</li>
          <li>Q3: What country is New York in? ‚Üí United States</li>
        </ol>
        <strong>Final Answer:</strong> United States
      </p>
    </div>
  </section>

  <section class="section">
  <div class="container">
    <h2 class="title is-3">Future Work</h2>
    <div class="content">
      <p>
        DeepSieve introduces a flexible backbone for modular RAG across heterogeneous knowledge sources. 
        Looking forward, we envision several exciting directions:
      </p>
      <ul>
        <li>üîÑ <strong>Personalized Routing:</strong> Allow users to upload their own corpora (e.g., SQL tables, OCR-ed PDFs, legal documents) with corresponding <code>profile</code> descriptions for dynamic tool selection.</li>
        <li>‚öñÔ∏è <strong>Legal Domain Extensions:</strong> Inspired by early feedback, legal research is a promising application. Queries often span statutes, case law, and regulatory sources ‚Äî a natural fit for source-aware subquestion routing.</li>
        <li>üß† <strong>Law Agents:</strong> Build agentic assistants that plan, retrieve, and reflect across structured and unstructured legal content ‚Äî enabling robust multi-hop legal reasoning.</li>
      </ul>
      <p>
        We believe these extensions will push RAG systems toward personalized, domain-aware, and self-reflective intelligence.
      </p>
    </div>
  </div>
</section>



  <section class="section">
  <div class="container">
    <h2 class="title is-3">Contact</h2>
    <p class="content">
      For general inquiries about this work, feel free to contact any of the authors listed above.  
      For technical issues or implementation questions, please open an issue on our <a href="https://github.com/MinghoKwok/DeepSieve" target="_blank">GitHub repository</a>.
    </p>
    <p class="content mt-3">
      You're also welcome to join the discussion on LinkedIn:<br>
      <a href="https://www.linkedin.com/posts/minghao-guo-181b4b168_rag-llm-multihopqa-activity-7356586902453387264-pPoM?utm_source=share&utm_medium=member_desktop&rcm=ACoAACgJUzEBrgPBqHZFVhD7Ebu7d9NeFVS5aWc" target="_blank">
        https://www.linkedin.com/posts/minghao-guo-181b4b168_rag-llm-multihopqa...
      </a>
    </p>
  </div>
</section>

</body>
</html>
