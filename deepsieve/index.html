<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>DeepSieve: Information Sieving via LLM-as-Router</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 40px auto; max-width: 900px; line-height: 1.7; color: #333; }
    h1, h2, h3 { color: #222; }
    .section { margin-bottom: 50px; }
    a { color: #007acc; text-decoration: none; }
    a:hover { text-decoration: underline; }
    code { background: #f2f2f2; padding: 2px 4px; border-radius: 4px; }
  </style>
</head>
<body>

  <h1>DeepSieve: Information Sieving via LLM-as-Knowledge-Router</h1>
  <p><a href="/">← Back to Home</a></p>

  <div class="section">
    <h2>Overview</h2>
    <p>
      <strong>DeepSieve</strong> is a modular, multi-hop RAG system that treats a Large Language Model (LLM) as a knowledge router.
      It performs query decomposition, source-aware routing, iterative reflexion, and final answer fusion—achieving improved retrieval precision, multi-step reasoning, and token efficiency across heterogeneous knowledge sources.
    </p>
    <p><strong>Code:</strong> <a href="https://anonymous.4open.science/r/DeepSieve" target="_blank">GitHub Repo (ACL Anonymous)</a></p>
  </div>

  <div class="section">
    <h2>Key Components</h2>
    <ol>
      <li><strong>Decompose</strong>: Use LLM to break complex queries into a DAG of structured sub-questions.</li>
      <li><strong>Route</strong>: Dynamically select the best (Tool, Corpus) pair for each subquestion.</li>
      <li><strong>Reflexion</strong>: Retry failed subqueries by re-routing to alternative sources.</li>
      <li><strong>Fusion</strong>: Aggregate all valid subanswers into a coherent final answer.</li>
    </ol>
  </div>

  <div class="section">
    <h2>Performance Highlights</h2>
    <p>
      DeepSieve outperforms both standard RAG baselines (e.g., IRCoT+HippoRAG, GraphRAG) and agentic methods (e.g., ReAct, Reflexion), while using significantly fewer tokens.
    </p>
    <ul>
      <li><strong>MuSiQue F1:</strong> 46.8 (+13.4↑ over best baseline)</li>
      <li><strong>2Wiki F1:</strong> 68.4 (+5.3↑)</li>
      <li><strong>HotpotQA F1:</strong> 61.6</li>
    </ul>
    <p><em>See paper for detailed ablation and efficiency comparisons.</em></p>
  </div>

  <div class="section">
    <h2>Example Case Study</h2>
    <p><strong>Query:</strong> What country is the birthplace of Erik Hort a part of?</p>
    <p><strong>Pure RAG:</strong> Guesses "United States" without evidence.</p>
    <p><strong>DeepSieve:</strong></p>
    <ul>
      <li>Q1: Who was born in Montebello? → Erik Hort</li>
      <li>Q2: What state is Montebello in? → New York</li>
      <li>Q3: What country is New York in? → United States</li>
    </ul>
    <p><strong>Final Answer:</strong> United States (with full traceability)</p>
  </div>

  <div class="section">
    <h2>Core Takeaways</h2>
    <ul>
      <li>✓ Modular design: plug-and-play tools, sources, and reasoning strategies.</li>
      <li>✓ Fine-grained source selection across SQL, JSON, Wiki, and private notes.</li>
      <li>✓ Significant gains in reasoning depth, precision, and efficiency.</li>
    </ul>
  </div>

  <div class="section">
    <h2>Contact</h2>
    <p>For questions, please contact: <code>minghao.guo@rutgers.edu</code></p>
  </div>

</body>
</html>
